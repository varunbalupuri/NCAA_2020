{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = pd.read_csv('data/mens/MTeams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_spellings = pd.read_csv('data/mens/MTeamSpellings.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teamname_to_teamid(teamname):\n",
    "        \n",
    "    mappings = {'Milwaukee': 'WI Milwaukee',\n",
    "                'WI Green Bay': 'Green Bay',\n",
    "                'Boston University': 'Boston Univ',\n",
    "               'Southern': 'Southern Univ',\n",
    "               'Cal St. Fullerton': 'CS Fullerton',\n",
    "               'Cal St. Northridge': 'CS Northridge',\n",
    "               'Cal St. Bakersfield': 'CS Bakersfield',\n",
    "               'Maryland Eastern Shore': 'MD E Shore',\n",
    "               'Mississippi Valley St.': 'MS Valley St',\n",
    "               'Illinois Chicago': 'IL Chicago',\n",
    "               'Arkansas Pine Bluff': 'Ark Pine Bluff',\n",
    "                'Arkansas Little Rock': 'Ark Little Rock',\n",
    "               'Southeast Missouri St.': 'SE Missouri St',\n",
    "               'Louisiana Monroe': 'ULM',\n",
    "               'Bethune Cookman': 'Bethune-Cookman',\n",
    "               'Texas A&M Corpus Chris': 'TAM C. Christi',\n",
    "                'Tennessee Martin': 'TN Martin',\n",
    "                'UT Rio Grande Valley': 'UTRGV',\n",
    "                'NJ Inst of Technology': 'NJIT',\n",
    "                'Virginia Military Inst': 'VMI',\n",
    "                'Missouri Kansas City': 'Missouri KC',\n",
    "                'Louisiana St.': 'LSU',\n",
    "                'Florida A&M;': 'Florida A&M',\n",
    "                'Wisconsin Milwaukee': 'WI Milwaukee',\n",
    "                'Nevada Las Vegas': 'UNLV',\n",
    "                'Alabama A&M;': 'Alabama A&M',\n",
    "                'Texas A&M; Corpus Chris': 'TAM C. Christi',\n",
    "                'North Carolina A&T;':'NC A&T',\n",
    "                'IUPU Fort Wayne': 'PFW',\n",
    "                'Wisconsin Green Bay': 'WI Green Bay',\n",
    "                'Texas El Paso': 'UTEP',\n",
    "                'Texas A&M;' : 'Texas A&M',\n",
    "                'Prairie View A&M;': 'Prairie View'\n",
    "               }\n",
    "    try:\n",
    "        teamname = mappings[teamname]\n",
    "    except KeyError:\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        teamid = teams[teams['TeamName'] == teamname].iloc[0]['TeamID']\n",
    "        return teamid\n",
    "    except (KeyError, IndexError):\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        teamid = teams[teams['TeamName'] == teamname.replace('.','')].iloc[0]['TeamID']\n",
    "        return teamid\n",
    "    except (KeyError, IndexError):\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        teamid = teams[teams['TeamName'] == teamname.replace(\"'\",\"\")].iloc[0]['TeamID']\n",
    "        return teamid\n",
    "    except (KeyError, IndexError):\n",
    "        pass\n",
    "    \n",
    "    if teamname.endswith('St.'):\n",
    "        try:\n",
    "            teamid = teams[teams['TeamName'] == teamname.rstrip('.')].iloc[0]['TeamID']\n",
    "            return teamid\n",
    "        except (KeyError, IndexError):\n",
    "            pass\n",
    "\n",
    "    try:\n",
    "        teamid = teams_spellings[teams_spellings['TeamNameSpelling'] == teamname.lower()].iloc[0]['TeamID']\n",
    "        return teamid\n",
    "    except (KeyError, IndexError):\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        teamid = teams_spellings[teams_spellings['TeamNameSpelling'] == teamname.lower().replace('.','')].iloc[0]['TeamID']\n",
    "        return teamid\n",
    "    except (KeyError, IndexError):\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PiT_urls = {2011: 'https://web.archive.org/web/20110228211802/https://kenpom.com/',\n",
    "           2012: 'https://web.archive.org/web/20120301065140/https://kenpom.com/',\n",
    "           2013: 'https://web.archive.org/web/20130301122807/https://kenpom.com/',\n",
    "           2014: 'https://web.archive.org/web/20140301071232/https://kenpom.com/',\n",
    "           2015: 'https://web.archive.org/web/20150228131430/https://kenpom.com/',\n",
    "           2016: 'https://web.archive.org/web/20160301131933/http://kenpom.com/',\n",
    "           2017: 'https://web.archive.org/web/20170301072239/https://kenpom.com/',\n",
    "           2018: 'https://web.archive.org/web/20180301162901/https://kenpom.com/',\n",
    "           2019: 'https://web.archive.org/web/20190301160638/https://kenpom.com/',\n",
    "           2020:'https://kenpom.com/index.php'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_match_kenpoms(year=2020):\n",
    "    url = PiT_urls[year]\n",
    "    dfs = pd.read_html(url)\n",
    "    if len(dfs[0].columns) > 20:\n",
    "        df = dfs[0]\n",
    "    elif len(dfs[1].columns) > 20:\n",
    "        df = dfs[1]\n",
    "    elif len(dfs[-1].columns) > 20:\n",
    "        df = dfs[-1]\n",
    "    real_cols = [df.columns[i][-1].replace('.1','') for i in range(len(df.columns))]\n",
    "    df.columns = real_cols\n",
    "    df = df.loc[:,~df.columns.duplicated()]\n",
    "    df = df[~pd.isna(df['Team'])]\n",
    "    df['Team'] = df['Team'].apply(lambda x: ''.join([i for i in x if not i.isdigit()]))\n",
    "    df['Team'] = df['Team'].apply(lambda x: x.rstrip(' '))\n",
    "    df['TeamID'] = df['Team'].apply(lambda x: teamname_to_teamid(x))\n",
    "    df = df[~pd.isna(df['TeamID'])]\n",
    "    if 'AdjEM' not in df.columns:\n",
    "        df['AdjEM'] = df['AdjO'].apply(lambda x: float(x)) - df['AdjD'].apply(lambda x: float(x))\n",
    "        del df['Pyth']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011 (342, 12)\n",
      "2012 (342, 12)\n",
      "2013 (344, 12)\n",
      "2014 (349, 12)\n",
      "2015 (349, 12)\n",
      "2016 (350, 12)\n",
      "2017 (350, 12)\n",
      "2018 (350, 12)\n",
      "2019 (353, 12)\n",
      "2020 (352, 12)\n"
     ]
    }
   ],
   "source": [
    "all_dfs = {}\n",
    "for year in range(2011, 2021):\n",
    "    df = get_and_match_kenpoms(year=year)\n",
    "    all_dfs[year] = df\n",
    "    print(year, df.shape)\n",
    "    df.to_csv(f'data/mens/PiT_kenpoms_{year}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
